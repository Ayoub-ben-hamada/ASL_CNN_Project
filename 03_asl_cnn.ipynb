{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuvwj_tr3ZZN"
      },
      "source": [
        "# Classification d’images ASL avec un CNN\n",
        "Ce projet consiste à créer et entraîner un **réseau de neurones convolutionnel** pour classifier des images de la langue des signes américaine (ASL).  \n",
        "**Objectifs :**\n",
        "- Préparer les données pour un modèle CNN.\n",
        "- Concevoir un CNN performant avec plusieurs types de couches.\n",
        "- Entraîner et évaluer le modèle sur un jeu de données d’images ASL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import des bibliothèques et configuration GPU"
      ],
      "metadata": {
        "id": "MBfzRKmuUbaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kMRTHEV2AFm",
        "outputId": "66bada66-31fb-4a01-8d3b-1234832a5778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Détection du device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEGukATl3ZZN"
      },
      "source": [
        "2. Chargement et préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMMgEMcc2Ehg"
      },
      "outputs": [],
      "source": [
        "# Chargement des datasets\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"/content/drive/MyDrive/sign_mnist_valid.csv\")\n",
        "\n",
        "\n",
        "# Paramètres images\n",
        "IMG_HEIGHT = 28\n",
        "IMG_WIDTH = 28\n",
        "IMG_CHS = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8kPbykZSgiv"
      },
      "source": [
        "2.1 Visualiser un échantillon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoWPEpIzSgiv",
        "outputId": "f23238bf-6a32-41f7-c89e-d11cafe6ecc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape des images : (5, 1, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "sample_df = train_df.head().copy()\n",
        "sample_df.pop('label')\n",
        "sample_x = sample_df.values\n",
        "sample_x = sample_x.reshape(-1, IMG_CHS, IMG_HEIGHT, IMG_WIDTH)\n",
        "print(\"Shape des images :\", sample_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01bbHIzOSgiw"
      },
      "source": [
        "3. Création du Dataset personnalisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tpzGOri32Klj"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, base_df):\n",
        "        x_df = base_df.copy()\n",
        "        y_df = x_df.pop('label')\n",
        "        x_df = x_df.values / 255 # Normalisation\n",
        "        x_df = x_df.reshape(-1, IMG_CHS, IMG_HEIGHT, IMG_WIDTH)\n",
        "        self.xs = torch.tensor(x_df).float().to(device)\n",
        "        self.ys = torch.tensor(y_df).to(device)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.xs[idx]\n",
        "        y = self.ys[idx]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adjXlP1LSgiw"
      },
      "source": [
        "4. Création des DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4xylt03dz1W",
        "outputId": "e54b2b4b-85fc-4ceb-b6dd-ab8f6ae9f030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape du batch d'images : torch.Size([32, 1, 28, 28])\n",
            "Shape du batch de labels : torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Création des datasets\n",
        "train_data = MyDataset(train_df)\n",
        "valid_data = MyDataset(valid_df)\n",
        "\n",
        "# Création des DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True pour mélanger les données\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)  # validation n'a pas besoin de shuffle\n",
        "\n",
        "# Vérification d'un batch\n",
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "\n",
        "print(\"Shape du batch d'images :\", images.shape)  # (batch_size, channels, height, width)\n",
        "print(\"Shape du batch de labels :\", labels.shape)  # (batch_size,)\n",
        "\n",
        "# Nombre total d'exemples\n",
        "train_N = len(train_loader.dataset)\n",
        "valid_N = len(valid_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vannMV7sd6R_",
        "outputId": "ad97cf30-4c91-4ccf-a380-11fe3827ef96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "batch[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHJgP3A7d9lu",
        "outputId": "df3a7295-8d09-4725-880e-3b5fa54e6ec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "batch[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6biSPXKJ3ZZP"
      },
      "source": [
        "5. Création du modèle CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p_bvGpMId_6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbc1b88-a7cc-403c-923a-d053aeae3e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OptimizedModule(\n",
            "  (_orig_mod): Sequential(\n",
            "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0.2, inplace=False)\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(50, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (13): Flatten(start_dim=1, end_dim=-1)\n",
            "    (14): Linear(in_features=675, out_features=512, bias=True)\n",
            "    (15): Dropout(p=0.3, inplace=False)\n",
            "    (16): ReLU()\n",
            "    (17): Linear(in_features=512, out_features=24, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "n_classes = 24\n",
        "kernel_size = 3\n",
        "flattened_img_size = 75 * 3 * 3\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # First convolution\n",
        "    nn.Conv2d(IMG_CHS, 25, kernel_size, stride=1, padding=1),  # 25 x 28 x 28\n",
        "    nn.BatchNorm2d(25),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),  # 25 x 14 x 14\n",
        "    # Second convolution\n",
        "    nn.Conv2d(25, 50, kernel_size, stride=1, padding=1),  # 50 x 14 x 14\n",
        "    nn.BatchNorm2d(50),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(.2),\n",
        "    nn.MaxPool2d(2, stride=2),  # 50 x 7 x 7\n",
        "    # Third convolution\n",
        "    nn.Conv2d(50, 75, kernel_size, stride=1, padding=1),  # 75 x 7 x 7\n",
        "    nn.BatchNorm2d(75),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, stride=2),  # 75 x 3 x 3\n",
        "    # Flatten to Dense\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(flattened_img_size, 512),\n",
        "    nn.Dropout(.3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, n_classes)\n",
        ")\n",
        "model = torch.compile(model.to(device))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Définition de la loss et de l’optimiseur"
      ],
      "metadata": {
        "id": "9RP-KryDYTAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters())"
      ],
      "metadata": {
        "id": "RFOkrbgZYYX3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Fonction d’évaluation de précision"
      ],
      "metadata": {
        "id": "9Hlu87uDYbpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_accuracy(output, y, N):\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  correct = pred.eq(y.view_as(pred)).sum().item()\n",
        "  return correct / N"
      ],
      "metadata": {
        "id": "HxTjiC0GYixC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Fonctions d’entraînement et de validation"
      ],
      "metadata": {
        "id": "-lc-TB0gYsGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.eval()  # met le modèle en mode évaluation\n",
        "    with torch.no_grad():  # pas de calcul du gradient\n",
        "        for x, y in valid_loader:\n",
        "            output = model(x)\n",
        "            loss += loss_function(output, y).item()\n",
        "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
        "\n",
        "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))\n"
      ],
      "metadata": {
        "id": "kNMT3McBYtOZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    model.train()  # mode entraînement\n",
        "    for x, y in train_loader:\n",
        "        output = model(x)\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = loss_function(output, y)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss += batch_loss.item()\n",
        "        accuracy += get_batch_accuracy(output, y, train_N)\n",
        "\n",
        "    # Print à l'intérieur de la fonction\n",
        "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))\n"
      ],
      "metadata": {
        "id": "dzm5JI9ZZAX4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Entraînement du modèle"
      ],
      "metadata": {
        "id": "ZD67Mh5BZPB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    train()\n",
        "    validate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7i-EYfPZOxV",
        "outputId": "b046d020-9c2a-486e-99b9-914bbb8a7bb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W1121 19:54:50.075000 819 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Loss: 242.0406 Accuracy: 0.9186\n",
            "Valid - Loss: 31.3478 Accuracy: 0.9451\n",
            "Epoch 2/20\n",
            "Train - Loss: 16.9846 Accuracy: 0.9946\n",
            "Valid - Loss: 41.4157 Accuracy: 0.9406\n",
            "Epoch 3/20\n",
            "Train - Loss: 4.3831 Accuracy: 0.9987\n",
            "Valid - Loss: 12.6675 Accuracy: 0.9826\n",
            "Epoch 4/20\n",
            "Train - Loss: 15.5492 Accuracy: 0.9947\n",
            "Valid - Loss: 31.7860 Accuracy: 0.9601\n",
            "Epoch 5/20\n",
            "Train - Loss: 6.1483 Accuracy: 0.9981\n",
            "Valid - Loss: 32.2951 Accuracy: 0.9578\n",
            "Epoch 6/20\n",
            "Train - Loss: 10.8619 Accuracy: 0.9958\n",
            "Valid - Loss: 25.4081 Accuracy: 0.9591\n",
            "Epoch 7/20\n",
            "Train - Loss: 7.9792 Accuracy: 0.9974\n",
            "Valid - Loss: 44.0583 Accuracy: 0.9347\n",
            "Epoch 8/20\n",
            "Train - Loss: 5.9468 Accuracy: 0.9980\n",
            "Valid - Loss: 33.5864 Accuracy: 0.9590\n",
            "Epoch 9/20\n",
            "Train - Loss: 4.8300 Accuracy: 0.9983\n",
            "Valid - Loss: 23.1903 Accuracy: 0.9695\n",
            "Epoch 10/20\n",
            "Train - Loss: 6.0722 Accuracy: 0.9981\n",
            "Valid - Loss: 15.6423 Accuracy: 0.9855\n",
            "Epoch 11/20\n",
            "Train - Loss: 5.9394 Accuracy: 0.9981\n",
            "Valid - Loss: 30.4999 Accuracy: 0.9625\n",
            "Epoch 12/20\n",
            "Train - Loss: 4.3492 Accuracy: 0.9984\n",
            "Valid - Loss: 57.8692 Accuracy: 0.9451\n",
            "Epoch 13/20\n",
            "Train - Loss: 1.9501 Accuracy: 0.9993\n",
            "Valid - Loss: 16.7060 Accuracy: 0.9777\n",
            "Epoch 14/20\n",
            "Train - Loss: 5.8063 Accuracy: 0.9981\n",
            "Valid - Loss: 21.3170 Accuracy: 0.9679\n",
            "Epoch 15/20\n",
            "Train - Loss: 5.5164 Accuracy: 0.9984\n",
            "Valid - Loss: 22.0621 Accuracy: 0.9706\n",
            "Epoch 16/20\n",
            "Train - Loss: 0.9413 Accuracy: 0.9997\n",
            "Valid - Loss: 18.8824 Accuracy: 0.9777\n",
            "Epoch 17/20\n",
            "Train - Loss: 4.9540 Accuracy: 0.9983\n",
            "Valid - Loss: 22.2046 Accuracy: 0.9664\n",
            "Epoch 18/20\n",
            "Train - Loss: 1.9062 Accuracy: 0.9994\n",
            "Valid - Loss: 20.3638 Accuracy: 0.9699\n",
            "Epoch 19/20\n",
            "Train - Loss: 4.0211 Accuracy: 0.9988\n",
            "Valid - Loss: 14.9161 Accuracy: 0.9834\n",
            "Epoch 20/20\n",
            "Train - Loss: 0.4411 Accuracy: 0.9999\n",
            "Valid - Loss: 15.4158 Accuracy: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Résultats"
      ],
      "metadata": {
        "id": "VAPpl1obZYgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle CNN atteint une bonne précision sur l’ensemble d’entraînement et l’ensemble de validation. Cette approche permet de mieux généraliser que les modèles plus simples et constitue une base solide pour d’autres projets de classification d’images.\n"
      ],
      "metadata": {
        "id": "8AFAHse9Zano"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}